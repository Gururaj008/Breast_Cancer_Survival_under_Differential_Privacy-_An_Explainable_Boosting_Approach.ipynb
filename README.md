# Breast Cancer Survival under Differential Privacy: An Explainable Boosting Approach

> **Protecting patient privacy while delivering powerful survival predictions.**

---

## ðŸš€ Overview

Building predictive models on clinical and genomic data offers lifeâ€‘saving insightsâ€”but safeguarding patient privacy is paramount. This project demonstrates how to train an **Explainable Boosting Machine (EBM)** under **Differential Privacy (DP)** guarantees, striking a clear **privacyâ€“utility tradeâ€‘off** in breast cancer survival modeling.

---

## ðŸŽ¯ Why This Matters

- **Privacy Regulations**: GDPR, HIPAA, and ethical research mandates require strong privacy safeguards on sensitive health data.  
- **Clinical Impact**: Predicting 5â€‘year survival can guide treatment planning and patient counseling.  
- **Research Frontier**: Differentially Private ML on real biomedical data is a hot topicâ€”few endâ€‘toâ€‘end tutorials exist.

---

## ðŸ“¦ Input Data

1. **Clinical Data (TSV)**  
   - METABRIC cohort: demographics, tumor stage, treatment details, survival times.  
2. **Genomic Data (CSV)**  
   - METABRIC RNA expression + mutation features (600+ numeric columns).  
3. **Survival Label**  
   - Binary indicator: survived beyond 60 months (`overall_survival_months > 60`).  

> All files are loaded from Google Drive in Colab, ensuring reproducibility.

---

## ðŸ›  Preâ€‘Processing Pipeline

1. **Merge & Clean**  
   - Read TSV/CSV, drop nonâ€‘numeric and unused columns.  
2. **Imputation & Scaling**  
   - Fill missing values with column means.  
   - Standardize features (`StandardScaler`).  
3. **Dimensionality Reduction**  
   - Apply PCA â†’ **10 principal components**.  
   - Focuses DP budget on strongest signals, reducing noise per feature.

---

## ðŸ¤– Models Employed

| Model                      | Key Parameters                          |
|----------------------------|-----------------------------------------|
| **Nonâ€‘private EBM**        | 100 boosting rounds, `n_jobs=-2`        |
| **DPâ€‘EBM**                 | Îµ âˆˆ {0.5,Â 1.0,Â 5.0}, 100 rounds, LR=0.01 |
| **Threshold Sweeper**      | 101 thresholds [0â€“1], maximize F1       |

- **Explainable Boosting Machine**: A glassâ€‘box GAM offering perâ€‘feature contributions.  
- **DPExplainableBoostingClassifier**: Adds noise to shapeâ€‘functions under a specified Îµ budget.  
- **Threshold Optimization**: Ensures we report best possible accuracy & F1 for each privacy setting.

---

## ðŸ“Š Results & Significance

| Îµ             | AUC    | Accuracy | F1     | Best Threshold |
|---------------|--------|----------|--------|----------------|
| **0.5 (DP)**  | 0.5892 | 0.7521   | 0.8585 | 0.00           |
| **1.0 (DP)**  | 0.5895 | 0.7542   | 0.8591 | 0.63           |
| **5.0 (DP)**  | 0.6343 | 0.7526   | 0.8588 | 0.64           |
| **Nonâ€‘private** | 0.6684 | 0.7537   | 0.8593 | 0.34           |

- **AUC vs. Îµ**: Low Îµ (0.5â€“1.0) injects heavy noise (AUC~0.59). By Îµ=5.0, performance recovers to ~0.63â€”just ~0.04 shy of the nonâ€‘private ceiling.  
- **Accuracy & F1**: Hover around 75%/0.86 as threshold tuning compensates for DP noiseâ€”ideal for decisionâ€‘level stability.  
- **Privacyâ€“Utility Tradeâ€‘off**: Visualized with crisp line plots, illustrating how increasing Îµ steadily recovers model utility.

---

